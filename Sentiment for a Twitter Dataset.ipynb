{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn \n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer \n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "positivepath = '/home/abdarhman/Downloads/Twitter/Positive/'\n",
    "positivefiles = [f for f in listdir(positivepath) if isfile(join(positivepath, f))]\n",
    "positivetweets = []\n",
    "for i in range(0,len(positivefiles)):\n",
    "    try:\n",
    "        positivetweets.append(open(join(positivepath, positivefiles[i]),encoding='utf-8-sig').read().rstrip())\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "print(len(positivetweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negativepath = '/home/abdarhman/Downloads/Twitter/Negative/'\n",
    "negativefiles = [f for f in listdir(negativepath) if isfile(join(negativepath, f))]\n",
    "negativetweets = []\n",
    "for i in range(0,len(negativefiles)):\n",
    "    try:\n",
    "        negativetweets.append(open(join(negativepath, negativefiles[i]),encoding='utf-8-sig').read().rstrip())\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "print(len(negativetweets))\n",
    "\n",
    "list(set(positivetweets).intersection(negativetweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1991 100 1865 100 1865 1865 100\n"
     ]
    }
   ],
   "source": [
    "T = []\n",
    "\n",
    "for i in range(0, len(positivetweets)):\n",
    "    T.append((positivetweets[i], 1))\n",
    "for i in range(0, len(negativetweets)):\n",
    "    T.append((negativetweets[i], 0))\n",
    "\n",
    "random.shuffle(T)\n",
    "\n",
    "T_Test = T[-100:]\n",
    "T_Train = T[:-100]\n",
    "\n",
    "T_Test = dict(T_Test)\n",
    "T_Train = dict(T_Train)\n",
    "\n",
    "X_Test = T_Test.keys()\n",
    "X_Train = T_Train.keys()\n",
    "\n",
    "\n",
    "Y_Test = list(T_Test.values())\n",
    "Y_Train = list(T_Train.values())\n",
    "\n",
    "print(len(T), len(T_Test), len(T_Train), len(X_Test), len(X_Train), len(Y_Train), len(Y_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF = TfidfVectorizer()\n",
    "TF = TF.fit(X_Train)\n",
    "V = TF.transform(X_Train)\n",
    "SGD = SGDClassifier()\n",
    "SGD.fit(V,Y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy =  0.87 ,   Training Accuracy =  0.9994638069705094\n"
     ]
    }
   ],
   "source": [
    "V_T = TF.transform(X_Test)\n",
    "C = 0\n",
    "C1 = 0\n",
    "for i in range(0,len(Y_Test)):\n",
    "    if SGD.predict(V_T[i])[0] == Y_Test[i]:\n",
    "        C = C + 1\n",
    "for i in range(0,len(Y_Train)):\n",
    "    if SGD.predict(V[i])[0] == Y_Train[i]:\n",
    "        C1 = C1 + 1\n",
    "        \n",
    "print ('Test Accuracy = ', C/len(Y_Test), ',   Training Accuracy = ', C1/len(Y_Train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
